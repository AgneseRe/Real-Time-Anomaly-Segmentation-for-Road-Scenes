{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgneseRe/Real-Time-Anomaly-Segmentation-for-Road-Scenes/blob/main/AML_AnomalySegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Real-time Anomaly Segmentation for Road Scenes**"
      ],
      "metadata": {
        "id": "xjyXaByVOtbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r sample_data/"
      ],
      "metadata": {
        "id": "SOBJKZAfEwAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existing deep neural networks, when deployed in open-world settings, perform poorly on unknown, anomaly, out-of-distribution (OoD) objects that were not present during the training. The goal of this project is to build tiny anomaly segmentation models to segment anomaly patterns. Models must be able to fit in small devices, which represents a realistic memory constraint for an edge application."
      ],
      "metadata": {
        "id": "XpweY-zTOyvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation"
      ],
      "metadata": {
        "id": "XxuFk3f4uqwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download required packages and import useful modules\n",
        "!pip3 install --quiet cityscapesscripts\n",
        "!pip3 install --quiet gdown\n",
        "!pip3 install --quiet numpy\n",
        "!pip3 install --quiet matplotlib\n",
        "!pip3 install --quiet Pillow\n",
        "!pip3 install --quiet torchvision\n",
        "!pip3 install --quiet visdom\n",
        "!pip3 install --quiet ood_metrics\n",
        "\n",
        "import os, sys, subprocess"
      ],
      "metadata": {
        "id": "Wed7tVmrP222",
        "outputId": "d3538219-c4dd-424d-f2fb-3554e5b67949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.6/473.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is implemented to download the *Cityscapes* dataset in two different ways: via Google Drive (using `gdown`) or directly from the Cityscapes official website (using `csDownload`). Although the first option is preferable as it is definitely faster, direct download from the website is provided as an alternative. `gdown` may in fact raise the error *Failed to retrieve the file url* if the file we are attempting to download is exceptionally large (*e.g.* 11G), there are numerous users simultaneously trying to download it programmatically or we download it many times in a limited time. Regardless of the method used, use the conversor (available [here](https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/preparation/createTrainIdLabelImgs.py)) to generate labelTrainIds from labelIds."
      ],
      "metadata": {
        "id": "aha0ydTyO4IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_cityscapes():\n",
        "\n",
        "    if not os.path.isdir('/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/cityscapes'):\n",
        "        print(\"Attempting to download cityscapes dataset using gdown...\")\n",
        "\n",
        "        try:\n",
        "            # If check is true, and the process exits with a non-zero exit code, a CalledProcessError exception will be raised.\n",
        "            subprocess.run([\"gdown\", \"https://drive.google.com/uc?id=11gSQ9UcLCnIqmY7srG2S6EVwV3paOMEq\"], check=True)\n",
        "            print(\"Dataset downloaded successfully using gdown. Unzipping...\")\n",
        "            subprocess.run([\"unzip\", \"-q\", \"cityscapes.zip\"], check=True)\n",
        "            # Use the conversor to generate labelTrainIds from labelIds\n",
        "            print(\"Generating trainIds from labelIds...\")\n",
        "            !CITYSCAPES_DATASET='cityscapes/' csCreateTrainIdLabelImgs\n",
        "\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(\"gdown failed. Attempting to download cityscapes dataset from the official website...\")\n",
        "            try:\n",
        "              # Cityscapes credentials: (agnesere, FCSBwcVMi-u9-Zn)\n",
        "              !csDownload leftImg8bit_trainvaltest.zip\n",
        "              !csDownload gtFine_trainvaltest.zip\n",
        "\n",
        "              print(\"Dataset downloaded successfully from the official website. Unzipping...\")\n",
        "              !unzip -q 'leftImg8bit_trainvaltest.zip' -d 'cityscapes'\n",
        "              !unzip -o -q 'gtFine_trainvaltest.zip' -d 'cityscapes'\n",
        "\n",
        "              print(\"Generating trainIds from labelIds...\")\n",
        "              !CITYSCAPES_DATASET='cityscapes/' csCreateTrainIdLabelImgs\n",
        "\n",
        "              print(\"Cityscapes dataset ready\")\n",
        "\n",
        "            except Exception as e2:\n",
        "                print(\"Failed to download the dataset using both methods.\")"
      ],
      "metadata": {
        "id": "-cQRn0hfGLlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and unzip the validation dataset (*FS_LostFound_full*, *RoadAnomaly*, *RoadAnomaly21*, *RoadObsticle21*, *fs_static*), clone or update the GitHub repository (*Real-Time-Anomaly-Segmentation-for-Road-Scenes*) and download the *Cityscapes* dataset."
      ],
      "metadata": {
        "id": "NFHf3bXySHFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download and unzip validation dataset\n",
        "if not os.path.isdir('/content/validation_dataset'):\n",
        "  !gdown 'https://drive.google.com/uc?id=12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta'\n",
        "  !unzip -q 'Validation_Dataset.zip'\n",
        "  !mkdir validation_dataset && cp -pR Validation_Dataset/* validation_dataset/ && rm -R Validation_Dataset/\n",
        "  !rm 'Validation_Dataset.zip'\n",
        "\n",
        "# clone the github repo and pull command\n",
        "if not os.path.isdir('content/Real-Time-Anomaly-Segmentation-for-Road-Scenes'):\n",
        "  !git clone https://github.com/AgneseRe/Real-Time-Anomaly-Segmentation-for-Road-Scenes.git\n",
        "else: # if folder already present\n",
        "  !git pull\n",
        "\n",
        "%cd Real-Time-Anomaly-Segmentation-for-Road-Scenes"
      ],
      "metadata": {
        "id": "Y_Bl3WGlWfon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download cityscapes dataset\n",
        "download_cityscapes()"
      ],
      "metadata": {
        "id": "AtojfyyxIpaw",
        "outputId": "58aca98d-6fc5-4d8e-97c8-14e0d3d5696f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download cityscapes dataset using gdown...\n",
            "Dataset downloaded successfully using gdown. Unzipping...\n",
            "Generating trainIds from labelIds...\n",
            "Processing 5000 annotation files\n",
            "Progress: 100.0 % "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "_czbWkaraAdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2A - Compute AuPRC & FPR95TPR"
      ],
      "metadata": {
        "id": "smRtjvZQu0R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd eval"
      ],
      "metadata": {
        "id": "W9ewyGcSZ__2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcabc30-aa6e-4d54-9ac0-409216b93911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform various anomaly inferences using the pre-trained **ErfNet** model and anomaly segmentation test dataset provided. Different techniques are used (MSP, MaxLogit and MaxEntropy)."
      ],
      "metadata": {
        "id": "MUOPyLTmNxhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "methods_list = [\"msp\", \"maxlogit\", \"maxentropy\"]\n",
        "datasets_list = os.listdir(\"../../validation_dataset\")\n",
        "\n",
        "for dataset in datasets_list:\n",
        "  print(f\"{dataset} dataset\")\n",
        "  for method in methods_list:\n",
        "    print(f\"\\t- {method}\")\n",
        "    input_path = f\"../../validation_dataset/{dataset}/images/*.*\"\n",
        "    !python evalAnomaly.py --input={input_path} --method={method}\n",
        "  print(\"---------------------------------\")"
      ],
      "metadata": {
        "id": "5CoH7P5ukYN8",
        "outputId": "e9101f64-7985-4dc8-c64d-503955a04802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoadObsticle21 dataset\n",
            "\t- msp\n",
            "\t\tAUPRC score: 2.712\n",
            "\t\tFPR@TPR95: 64.974\n",
            "\t- maxlogit\n",
            "\t\tAUPRC score: 4.627\n",
            "\t\tFPR@TPR95: 48.443\n",
            "\t- maxentropy\n",
            "\t\tAUPRC score: 3.052\n",
            "\t\tFPR@TPR95: 65.600\n",
            "----------------------\n",
            "RoadAnomaly21 dataset\n",
            "\t- msp\n",
            "\t\tAUPRC score: 29.100\n",
            "\t\tFPR@TPR95: 62.511\n",
            "\t- maxlogit\n",
            "\t\tAUPRC score: 38.320\n",
            "\t\tFPR@TPR95: 59.337\n",
            "\t- maxentropy\n",
            "\t\tAUPRC score: 31.005\n",
            "\t\tFPR@TPR95: 62.593\n",
            "----------------------\n",
            "RoadAnomaly dataset\n",
            "\t- msp\n",
            "\t\tAUPRC score: 12.426\n",
            "\t\tFPR@TPR95: 82.492\n",
            "\t- maxlogit\n",
            "\t\tAUPRC score: 15.582\n",
            "\t\tFPR@TPR95: 73.248\n",
            "\t- maxentropy\n",
            "\t\tAUPRC score: 12.678\n",
            "\t\tFPR@TPR95: 82.632\n",
            "----------------------\n",
            "fs_static dataset\n",
            "\t- msp\n",
            "\t\tAUPRC score: 7.470\n",
            "\t\tFPR@TPR95: 41.823\n",
            "\t- maxlogit\n",
            "\t\tAUPRC score: 9.499\n",
            "\t\tFPR@TPR95: 40.300\n",
            "\t- maxentropy\n",
            "\t\tAUPRC score: 8.826\n",
            "\t\tFPR@TPR95: 41.523\n",
            "----------------------\n",
            "FS_LostFound_full dataset\n",
            "\t- msp\n",
            "\t\tAUPRC score: 1.748\n",
            "\t\tFPR@TPR95: 50.763\n",
            "\t- maxlogit\n",
            "\t\tAUPRC score: 3.301\n",
            "\t\tFPR@TPR95: 45.495\n",
            "\t- maxentropy\n",
            "\t\tAUPRC score: 2.582\n",
            "\t\tFPR@TPR95: 50.368\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2B - Compute AuPRC & FPR95TPR with temperature scaling"
      ],
      "metadata": {
        "id": "JJodGToyvAwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_list = os.listdir(\"../../validation_dataset\")\n"
      ],
      "metadata": {
        "id": "WNonHsRaG9Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_list = [0.5, 0.75, 1.0, 1.1, 1.2, 1.5, 2.0, 3.0, 5.0, 10.0, 50.0]\n",
        "\n",
        "for dataset in datasets_list:\n",
        "  print(f\"{dataset} dataset\")\n",
        "  for t in temperature_list:\n",
        "    print(f\"\\t- {t}\")\n",
        "    input_path = f\"../../validation_dataset/{dataset}/images/*.*\"\n",
        "    !python evalAnomaly.py --input={input_path} --method=\"msp\" --temperature={t}\n",
        "  print(\"---------------------------------\")"
      ],
      "metadata": {
        "id": "t5oNs1EqDL6B",
        "outputId": "ea571002-28f7-4c01-9807-551deecd12a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoadAnomaly21\n",
            "\t- 0.5\n",
            "\t\tAUPRC score: 27.061\n",
            "\t\tFPR@TPR95: 62.731\n",
            "\t- 0.75\n",
            "\t\tAUPRC score: 28.156\n",
            "\t\tFPR@TPR95: 62.479\n",
            "\t- 1.0\n",
            "\t\tAUPRC score: 29.100\n",
            "\t\tFPR@TPR95: 62.511\n",
            "\t- 1.1\n",
            "\t\tAUPRC score: 29.410\n",
            "\t\tFPR@TPR95: 62.590\n",
            "\t- 1.2\n",
            "\t\tAUPRC score: 29.678\n",
            "\t\tFPR@TPR95: 62.724\n",
            "\t- 1.5\n",
            "\t\tAUPRC score: 30.258\n",
            "\t\tFPR@TPR95: 63.318\n",
            "\t- 2.0\n",
            "\t\tAUPRC score: 30.679\n",
            "\t\tFPR@TPR95: 64.721\n",
            "\t- 3.0\n",
            "\t\tAUPRC score: 30.674\n",
            "\t\tFPR@TPR95: 67.682\n",
            "\t- 5.0\n",
            "\t\tAUPRC score: 30.196\n",
            "\t\tFPR@TPR95: 71.594\n",
            "\t- 10.0\n",
            "\t\tAUPRC score: 29.526\n",
            "\t\tFPR@TPR95: 75.757\n",
            "\t- 50.0\n",
            "\t\tAUPRC score: 28.804\n",
            "\t\tFPR@TPR95: 80.014\n",
            "FS_LostFound_full\n",
            "\t- 0.5\n",
            "\t\tAUPRC score: 1.280\n",
            "\t\tFPR@TPR95: 66.737\n",
            "\t- 0.75\n",
            "\t\tAUPRC score: 1.493\n",
            "\t\tFPR@TPR95: 51.848\n",
            "\t- 1.0\n",
            "\t\tAUPRC score: 1.748\n",
            "\t\tFPR@TPR95: 50.763\n",
            "\t- 1.1\n",
            "\t\tAUPRC score: 1.860\n",
            "\t\tFPR@TPR95: 50.387\n",
            "\t- 1.2\n",
            "\t\tAUPRC score: 1.972\n",
            "\t\tFPR@TPR95: 50.150\n",
            "\t- 1.5\n",
            "\t\tAUPRC score: 2.286\n",
            "\t\tFPR@TPR95: 49.456\n",
            "\t- 2.0\n",
            "\t\tAUPRC score: 2.677\n",
            "\t\tFPR@TPR95: 48.324\n",
            "\t- 3.0\n",
            "\t\tAUPRC score: 3.048\n",
            "\t\tFPR@TPR95: 46.893\n",
            "\t- 5.0\n",
            "\t\tAUPRC score: 3.252\n",
            "\t\tFPR@TPR95: 45.396\n",
            "\t- 10.0\n",
            "\t\tAUPRC score: 3.344\n",
            "\t\tFPR@TPR95: 44.121\n",
            "\t- 50.0\n",
            "\t\tAUPRC score: 3.388\n",
            "\t\tFPR@TPR95: 43.361\n",
            "fs_static\n",
            "\t- 0.5\n",
            "\t\tAUPRC score: 6.601\n",
            "\t\tFPR@TPR95: 43.476\n",
            "\t- 0.75\n",
            "\t\tAUPRC score: 6.991\n",
            "\t\tFPR@TPR95: 42.493\n",
            "\t- 1.0\n",
            "\t\tAUPRC score: 7.470\n",
            "\t\tFPR@TPR95: 41.823\n",
            "\t- 1.1\n",
            "\t\tAUPRC score: 7.687\n",
            "\t\tFPR@TPR95: 41.587\n",
            "\t- 1.2\n",
            "\t\tAUPRC score: 7.910\n",
            "\t\tFPR@TPR95: 41.406\n",
            "\t- 1.5\n",
            "\t\tAUPRC score: 8.580\n",
            "\t\tFPR@TPR95: 41.096\n",
            "\t- 2.0\n",
            "\t\tAUPRC score: 9.508\n",
            "\t\tFPR@TPR95: 41.018\n",
            "\t- 3.0\n",
            "\t\tAUPRC score: 10.529\n",
            "\t\tFPR@TPR95: 42.180\n",
            "\t- 5.0\n",
            "\t\tAUPRC score: 11.175\n",
            "\t\tFPR@TPR95: 45.514\n",
            "\t- 10.0\n",
            "\t\tAUPRC score: 11.462\n",
            "\t\tFPR@TPR95: 51.164\n",
            "\t- 50.0\n",
            "\t\tAUPRC score: 11.546\n",
            "\t\tFPR@TPR95: 58.587\n",
            "RoadObsticle21\n",
            "\t- 0.5\n",
            "\t\tAUPRC score: 2.420\n",
            "\t\tFPR@TPR95: 63.225\n",
            "\t- 0.75\n",
            "\t\tAUPRC score: 2.567\n",
            "\t\tFPR@TPR95: 64.053\n",
            "\t- 1.0\n",
            "\t\tAUPRC score: 2.712\n",
            "\t\tFPR@TPR95: 64.974\n",
            "\t- 1.1\n",
            "\t\tAUPRC score: 2.766\n",
            "\t\tFPR@TPR95: 65.524\n",
            "\t- 1.2\n",
            "\t\tAUPRC score: 2.816\n",
            "\t\tFPR@TPR95: 66.033\n",
            "\t- 1.5\n",
            "\t\tAUPRC score: 2.937\n",
            "\t\tFPR@TPR95: 67.928\n",
            "\t- 2.0\n",
            "\t\tAUPRC score: 3.026\n",
            "\t\tFPR@TPR95: 71.459\n",
            "\t- 3.0\n",
            "\t\tAUPRC score: 2.998\n",
            "\t\tFPR@TPR95: 76.800\n",
            "\t- 5.0\n",
            "\t\tAUPRC score: 2.841\n",
            "\t\tFPR@TPR95: 83.111\n",
            "\t- 10.0\n",
            "\t\tAUPRC score: 2.644\n",
            "\t\tFPR@TPR95: 88.146\n",
            "\t- 50.0\n",
            "\t\tAUPRC score: 2.448\n",
            "\t\tFPR@TPR95: 92.080\n",
            "RoadAnomaly\n",
            "\t- 0.5\n",
            "\t\tAUPRC score: 12.188\n",
            "\t\tFPR@TPR95: 82.022\n",
            "\t- 0.75\n",
            "\t\tAUPRC score: 12.319\n",
            "\t\tFPR@TPR95: 82.285\n",
            "\t- 1.0\n",
            "\t\tAUPRC score: 12.426\n",
            "\t\tFPR@TPR95: 82.492\n",
            "\t- 1.1\n",
            "\t\tAUPRC score: 12.466\n",
            "\t\tFPR@TPR95: 82.621\n",
            "\t- 1.2\n",
            "\t\tAUPRC score: 12.502\n",
            "\t\tFPR@TPR95: 82.757\n",
            "\t- 1.5\n",
            "\t\tAUPRC score: 12.591\n",
            "\t\tFPR@TPR95: 83.244\n",
            "\t- 2.0\n",
            "\t\tAUPRC score: 12.676\n",
            "\t\tFPR@TPR95: 84.150\n",
            "\t- 3.0\n",
            "\t\tAUPRC score: 12.715\n",
            "\t\tFPR@TPR95: 85.776\n",
            "\t- 5.0\n",
            "\t\tAUPRC score: 12.672\n",
            "\t\tFPR@TPR95: 87.713\n",
            "\t- 10.0\n",
            "\t\tAUPRC score: 12.575\n",
            "\t\tFPR@TPR95: 89.477\n",
            "\t- 50.0\n",
            "\t\tAUPRC score: 12.451\n",
            "\t\tFPR@TPR95: 91.006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - Train models with void classifier"
      ],
      "metadata": {
        "id": "6ylMHF05vI-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\"erfnet\", \"enet\", \"bisenet\"]\n"
      ],
      "metadata": {
        "id": "uvJ8DqNPGxg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "savedirs = [\"erfnet_training_void\", \"enet_training_void\", \"bisenet_training_void\"]\n",
        "pretrained_weights = [\"erfnet_pretrained.pth\", \"enet_pretrained.pth\", \"bisenetv1_pretrained.pth\"]\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"../train\"\n",
        "# Dataset directory\n",
        "data_dir = \"../cityscapes\"\n",
        "\n",
        "!cd {base_dir} && python main_v2.py --savedir \"bisenet_training_void\" --datadir {data_dir} --model \"bisenet\" --cuda --num-epochs=20 --epochs-save=1 --batch-size=6"
      ],
      "metadata": {
        "id": "lxoP9g7BF45G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "E8ATRy0qGNmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = False\n",
        "\n",
        "for model in models:\n",
        "  print(\"----------------------------\")\n",
        "  for dataset_dir in datasets_list:\n",
        "\n",
        "    if no_execute:\n",
        "      break\n",
        "\n",
        "    load_dir = f'content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/save/{net}_training_void'\n",
        "    weights = f'/model_best.pth'\n",
        "    format_file = os.listdir(f'/content/validation_dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/validation_dataset/{dataset_dir}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} net: {net}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      !python  content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --void --model {net} --loadDir {load_dir} --loadWeights {weights} | tail -n 2\n",
        "    else:\n",
        "      !python  content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --void --model {net} --loadDir {load_dir} --loadWeights {weights} --cpu | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False\n",
        ""
      ],
      "metadata": {
        "id": "hmjgpr8lGQ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mIoU Void Classification**"
      ],
      "metadata": {
        "id": "5TJKUFjWIbQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "no_execute = False\n",
        "just_once = False\n",
        "\n",
        "for model in models:\n",
        "  print(\"----------------------------\")\n",
        "\n",
        "  if no_execute:\n",
        "      break\n",
        "  print(f\"-----------{model}-------------\")\n",
        "  loadDir = f'content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/save/{model}_training_void'\n",
        "  weights = f'/model_best.pth'\n",
        "  if torch.cuda.is_available():\n",
        "    !python  content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/eval_iou.py --loadDir {loadDir} --loadWeights {weights} --datadir /content/cityscapes/ --model {model} | tail -n 25\n",
        "  else:\n",
        "    !python  content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/eval_iou.py  --loadDir {loadDir} --loadWeights {weights} --datadir /content/cityscapes/  --model {model}  --cpu | tail -n 25\n",
        "\n",
        "\n",
        "  if just_once:\n",
        "    no_execute = True\n",
        "    just_once = False"
      ],
      "metadata": {
        "id": "6tiSQNBxIl3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 - Analyze the Effect of Training Loss function"
      ],
      "metadata": {
        "id": "8n2SPIAyvU5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the effect of the training model along with losses that are specifically made for anomaly detection."
      ],
      "metadata": {
        "id": "dkwRPEbyVkKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Losses**"
      ],
      "metadata": {
        "id": "PEaQplsFKGqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning**"
      ],
      "metadata": {
        "id": "ACEmk07kKSzF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1eM-3aNyKYrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extension Evaluation**"
      ],
      "metadata": {
        "id": "1zIp0mbgKafh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eopXW5mKKeR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plot"
      ],
      "metadata": {
        "id": "O1JdbXZnKfyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example image to color\n",
        "# Nice images: RoadAnomaly/images/28, RoadAnomaly/images/58\n",
        "input = '/content/Validation_Dataset/RoadAnomaly/images/58.jpg'\n",
        "\n",
        "### Baseline models ###\n",
        "for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\", \"Mahalanobis\"]:\n",
        "  print(f\"Method: {method}\")\n",
        "  save_image_path = f'/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/baseline/{method}'\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --method  {method} --save-colored {save_image_path}  | tail -n 2\n",
        "  else:\n",
        "    !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --method {method} --save-colored {save_image_path} --cpu | tail -n 2\n",
        "\n",
        "!python /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/ccontent/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/baseline\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/baseline_visualization.png\"\n",
        "\n",
        "### Temperature scaling ###\n",
        "for t in [0.5, 0.75, 1.1]:\n",
        "  print(f\"Method: MSP, Temperature: {t}\")\n",
        "  save_image_path = f'/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/temperature/t={t}'\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --method 'MSP' --temperature {t} --save-colored {save_image_path} | tail -n 2\n",
        "  else:\n",
        "    !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --method 'MSP' --cpu --temperature {t} --save-colored {save_image_path} | tail -n 2\n",
        "\n",
        "!python /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/temperature\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/temperature_visualization.png\"\n",
        "\n",
        "### Finetuned models with void ###\n",
        "for net in [\"erfnet\", \"enet\", \"bisenet\"]:\n",
        "  save_image_path = f'/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/void/{net}'\n",
        "  load_dir = f'/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/save/{net}_training_void'\n",
        "  weights = f'/model_best.pth'\n",
        "  print(f\"Finetuned network: {net}\")\n",
        "  if torch.cuda.is_available():\n",
        "    !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --void --model {net} --loadDir {load_dir} --loadWeights {weights} --save-colored {save_image_path} | tail -n 2\n",
        "  else:\n",
        "    !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --void --model {net} --loadDir {load_dir} --loadWeights {weights} --cpu --save-colored {save_image_path} | tail -n 2\n",
        "\n",
        "!python /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/void\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/void_visualization.png\"\n",
        "\n",
        "### Losses ###\n",
        "losses = [\"CrossEntropy\", \"Focal\", \"LogitNorm\", \"IsoMaxPlus\"]\n",
        "models = [\"erfnet\", \"erfnet\", \"erfnet\", \"erfnet_isomaxplus\"]\n",
        "load_dirs = [\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/trained_models/\", \"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/save/erfnet_training_focal_loss/\", \"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/save/erfnet_training_logitnorm_loss/\", \"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/save/erfnet_training_isomaxplus_loss/\"]\n",
        "weights = [\"erfnet_pretrained.pth\", \"model_best.pth\", \"model_best.pth\", \"model_best.pth\"]\n",
        "for loss, model, load_dir, weight in zip(losses, models, load_dirs, weights):\n",
        "  for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\", \"Mahalanobis\"]:\n",
        "    save_image_path = f'/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses/{loss}/{method}'\n",
        "    print(f\"Method: {method}, loss: {loss}\")\n",
        "    if torch.cuda.is_available():\n",
        "      !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --method  {method} --model {model} --loadDir {load_dir} --loadWeights {weight} --save-colored {save_image_path} | tail -n 2\n",
        "    else:\n",
        "      !python  /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/evalAnomaly.py --input {input} --method {method}  --model {model} --loadDir {load_dir} --loadWeights {weight} --save-colored {save_image_path} --cpu | tail -n 2\n",
        "\n",
        "!python /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses/CrossEntropy\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses_CrossEntropy_visualization.png\"\n",
        "!python /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses/Focal\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses_Focal_visualization.png\"\n",
        "!python /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses/LogitNorm\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses_LogitNorm_visualization.png\"\n",
        "!python /ccontent/Real-Time-Anomaly-Segmentation-for-Road-Scenes/eval/visualization.py --name_dir=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses/IsoMaxPlus\" --name_output=\"/content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization/losses_IsoMaxPlus_visualization.png\"\n",
        "\n",
        "# Zip the images\n",
        "!zip -r colored_anomalies.zip /content/Real-Time-Anomaly-Segmentation-for-Road-Scenes/visualization"
      ],
      "metadata": {
        "id": "kh4XfFbnKkuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}